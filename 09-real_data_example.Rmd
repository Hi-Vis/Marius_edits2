# Real world data example

In this example, we'll use some data derived from a real study to get
some experience dealing with messy raw data [^simdata].

[^simdata]: All the data used here was simulated with
[synthpop](https://cran.r-project.org/web/packages/synthpop/index.html),
so it doesn't contain data from any actual participants.

Before we start, we'll install some packages:

```{r real_example_packages, eval=FALSE}
install.packages(c("readxl", "lme4"))
```

## Data overview

This data contains the post-treatment observations from a
cluster-randomised trial comparing a novel treatment to control.
Schools were randomised to different groups, so every
participant in the same school received the same
intervention. It contains:

* SURPS scores, a scale assessing different personality traits
  associated with substance use.
* The anxiety and depression subscales of the Brief Symptom Inventory
* Questions about alcohol use

The scales haven't been scored, so our first step will be scoring
them, before we move onto describing and analysing the data. 

```{block, type='note'}
Checking what you've just done is very useful after any
change you make to the data. Throughout this example, I'll
include notes on how you could check the previous step.
Try to code those checks yourself!
```

### SURPS overview

The SURPS scale has four subscales:

* Negative thinking/hopelessness
* Anxiety sensitivity
* Impulsivity
* Sensation seeking

Higher scores on each subscale represent higher levels
of the personality traits related to substance use, i.e.
greater risk.

### BSI overview

The study includes two subscales from the Brief Symptom Inventory.
Higher scores on each represent higher levels of symptoms:

* Depression
* Anxiety

## Basic setup

### Load libraries

As always, the first step is loading the libraries we'll use in this
analysis:

```{r real_load_libraries, message=FALSE}
library(tidyverse)
library(psych)
library(sjPlot)
library(readxl)
library(lme4)

# We'll also set a default theme for our
#   ggplot plots
theme_set(theme_bw())
```


### Load the data

The example data is available online - to download it you can use:

```{r download_real_data, eval=FALSE}
download.file("https://gitlab.com/warsquid/rad/raw/master/data/CapSimulatedData.xlsx",
              destfile = "CapSimulatedData.xlsx",
              mode = "wb")
```

(if that doesn't work, please manually download the file
[here](https://gitlab.com/warsquid/rad/raw/master/data/CapSimulatedData.xlsx)
and copy it to your project directory)

Now we can load the data in:

```{r load_real_data, eval=FALSE}
real = readxl::read_excel("CapSimulatedData.xlsx")
head(real)
```

```{r load_real_server, echo=FALSE}
# When building the book/running in development, just
#   load the data from the local folder rather than downloading
#   it
real = readxl::read_excel("data/CapSimulatedData.xlsx")
head(real)
```

A good first step is to use `str()` to inspect the data types:

```{r real_str, results='hide'}
str(real)
```

And check some basic features of the data like the number of people
in each intervention group (and maybe school?).

```{r real_numchecks, options}
table(real$Group)
table(real$SchoolId)
```

### Solve major issues

One major issue with this data is that not everyone completed the
post-treatment assessment, and they have missing data for all
the questions. In an in-depth analysis we might try to handle
this missing data in a more sophisticated way, but for now there's
not much we can do with it, so we'll drop it up front:

```{r drop_nonpresent, options}
# Same as:
# real = real[real$PresentPost == 1, ]
real = filter(real, PresentPost == 1)
```

This is a contrived example, but if you can do something
to simplify your data like this, it's best to do it up front,
before getting into the details of data cleaning and analysis.

## Recoding and scoring

### Scoring SURPS the easy way

Sometimes there are existing functions in R or in packages that people
have written that do exactly what we want with minimal effort.

The `psych::scoreItems()` function is designed for scoring psychometric
scales, and it has options to allow a few common tweaks to the scoring
process, so it will often score things exactly how you want them.

The most useful feature of `scoreItems()` is it allows you to specify the questions
that make up each subscale by providing a **list**: each element
of the list is a **character vector** specifying which questions
are in that subscale. You can put a `-` in front of a question
if that question should be **reverse scored**.

So a simple scale with two subscales might look like:

```{r scoreitems_example, eval=FALSE}
scoring_key = list(
    Extraversion = c("Q1", "-Q2", "Q3"),
    Introversion = c("-Q4", "-Q5", "Q6")
)
```

The SURPS questionnaire has four subscales, and we can score them all at once
using:

```{r psych_simple_surps, options}
surps_keys = list(
    Nt = c("-Surps1", "-Surps4", "-Surps7", "-Surps13", 
           "Surps17", "-Surps20", "-Surps23"),
    As = c("Surps8", "Surps10", "Surps14", "Surps18", 
           "Surps21"),
    Imp = c("Surps2", "Surps5", "Surps11", "Surps15", 
            "Surps22"),
    Ss = c("Surps3", "Surps6", "Surps9", "Surps12", 
               "Surps16", "Surps19")
)

surps_scored = psych::scoreItems(
    keys = surps_keys, 
    items = real,
    totals = TRUE,
    impute = "median")
```

We have the scores now, but we haven't added them to our main dataset yet.
We can look at the object that `scoreItems()` has given us:

```{r psych_inspect_scores, results='hide'}
surps_scored
```

This is a lot of information, and right now we're only interested in the scores,
so we need to check how to access them.

Looking at the help page `?scoreItems` under the **Value** section tells us the 
actual scores are stored at `surps_scored$scores`. We can add all 4 columns into
our dataset at once with:

```{r psych_bind_results, options}
real[, c("NtTotal", "AsTotal", "ImpTotal", "SsTotal")] = surps_scored$scores
head(real[, c("NtTotal", "AsTotal", "ImpTotal", "SsTotal")])
```

```{block, type='note'}
Sometimes you don't need all the extra info that `psych::scoreItems()` provides.
`psych::scoreFast()` will do the same calculations but just return the final
scores.
```

### Scoring SURPS the harder way

Functions like `scoreItems()` won't always do exactly what we want.
When we scored the scales above, we let `scoreItems()` impute any missing
values using that item's median score. However, if we have our own missing
data procedure that doesn't match what `scoreItems()` does, we might have
to do some of the work ourselves.

One scoring procedure I've used in the past is:

* Calculate the scale total for participants who answer all questions
* Participants that answer fewer than 80% of a scale's items get a missing value
* Participants that answer more than 80% of items get their scores "expanded"
  to match the full range based on all items.
  
Some basic math tells us that for those participants who answer >=80% of items,
we can calculate the mean of the items they did answer and multiply by the
total number of items.

To implement our custom procedure, we can do:

```{r psych_scoreitems_custom, options}
surps_manual = psych::scoreItems(
    keys = surps_keys, 
    items = real,
    totals = FALSE, # Calculate the mean score
    impute = "none")

real$NtManual = surps_manual$scores[, "Nt"] * length(surps_keys[["Nt"]])
# Set missing when less than 80% of items scored
real$NtManual[surps_manual$missing[, "Nt"] > 1] = NA

real$AsManual = surps_manual$scores[, "As"] * length(surps_keys[["As"]])
real$AsManual[surps_manual$missing[, "As"] > 1] = NA

real$ImpManual = surps_manual$scores[, "Imp"] * length(surps_keys[["Imp"]])
real$ImpManual[surps_manual$missing[, "Imp"] > 1] = NA

real$SsManual = surps_manual$scores[, "Ss"] * length(surps_keys[["Ss"]])
real$SsManual[surps_manual$missing[, "Ss"] > 1] = NA
```

Note how we can use R to calculate some of the numbers involved automatically,
like using `length(surps_keys[["Nt"]])` instead of typing the actual number.
Reusing information that we've already stored can save us from dumb mistakes,
since as long as we check that `surps_keys` has the right items, every piece
of code that uses it should also have the right information.

How can we figure out the maximum number of missing items for each scale?
R can help us with that too:

```{r calc_missing_nums, options}
sapply(surps_keys, function(items) {
    # ceiling() rounds up
    min_items = ceiling(0.8 * length(items))
    max_missing = length(items) - min_items
    return(max_missing)
})
```

As you get more comfortable with R, you can start using it not just
to manage your data, but to do some of the extra tasks and calculations that
pop up in the process.

```{block, type='note'}
A simple way to check the scoring would be to look at all the items from
one of the subscales along with the total score - calculate
a couple of scores manually and see if they match.
```

### Scoring the BSI scales

We can score the BSI scales the same way. We just want the total
for each subscale, and we'll assume `psych`'s median imputation
is OK:

```{r bsi_scoring_example, options}
bsi_keys = list(
    # Using 'paste0' to create the column names for us
    Dep = paste0("Bsi", 1:6),
    Anx = paste0("Bsi", 7:10)
)

bsi_scored = psych::scoreItems(
    keys = bsi_keys, 
    items = real,
    totals = TRUE,
    impute = "median")

real[, c("DepTotal", "AnxTotal")] = bsi_scored$scores
head(real[, c("DepTotal", "AnxTotal")])
```

### Recoding

#### Recoding categories

All the basic recoding tools you'd expect are available in R. The most basic
tool is converting numeric codes for categorical variables into nicely
labelled factors:

```{r factor_recode_example, options}
real$SipEver = factor(
    real$SipEver,
    levels = c(0, 1),
    labels = c("No", "Yes")
)

real$FullEver = factor(
    real$FullEver,
    levels = c(0, 1),
    labels = c("No", "Yes")
)

real$Sip6 = factor(
    real$Sip6,
    levels = c(0, 1),
    labels = c("No", "Yes")
)

real$Full6 = factor(
    real$Full6,
    levels = c(0, 1),
    labels = c("No", "Yes")
)

real$Full6_freq = factor(
    real$Full6_freq,
    levels = c(0, 1, 2, 3, 4, 5),
    labels = c("Never", "Less than monthly", "Monthly", 
               "1-2 times a month", "Weekly",
               "Daily")
)

head(real[, c("SipEver", "FullEver", "Sip6", "Full6", "Full6_freq")])
```

Once you've converted the variables to factors, you can combine
and reorder categories in different ways using functions
from the `forcats` package (part of the `tidyverse`). If
we want to simplify the frequency variable so it's just
a Yes/No variable reflecting whether the participant drinks
monthly or more often:

```{r real_forcats_example, options}
real$Full6_monthly = fct_collapse(
  real$Full6_freq,
  Monthly = c("Monthly", "1-2 times a month", 
              "Weekly","Daily"),
  Less = c("Never", "Less than monthly")
)
```

```{block, type='note'}
A good way to check this recoding would be to check
the total numbers for each response for each variable.
```

##### Advanced tip: Avoid repeating yourself {-}

In the code above we do the exact same thing repeatedly,
just changing the column name each time. R has lots of
great tools for applying the same steps multiple times,
which become very useful as your data gets larger.
The [tidyverse](#tidyverse) has some particularly
great tools to make this easier.

If we turn the steps for coding a yes/no variable into
a **function** we could apply it to all columns at once,
using `mutate_at` from the `dplyr` package:

```{r recode_function_example, eval=FALSE}
# Does the same as the No/Yes recoding above
real = mutate_at(
    real,
    vars(c("SipEver", "FullEver", "Sip6", "Full6")),
    function(col) {
        factor(col,
               levels = c(0, 1),
               labels = c("No", "Yes"))
    }
)
```

#### Scaling/Calculating z-scores {-}

The `scale()` function converts scores to z-scores by mean-centering
them and dividing them by their standard deviation. `scale()` returns
a **matrix** even when we only call it on a single vector, so we need
a bit of extra syntax to pull the values out of the matrix:

```{r scaling_example, options}
real$NtTotal_z = scale(real$NtTotal)[, 1]
real$AsTotal_z = scale(real$AsTotal)[, 1]
real$ImpTotal_z = scale(real$ImpTotal)[, 1]
real$SsTotal_z = scale(real$SsTotal)[, 1]

head(real[, c("NtTotal", "NtTotal_z", "AsTotal", "AsTotal_z")])
```

```{block, type='note'}
The resulting variables should have means of (very close to) 0 and SDs
of 1 - check them by calculating.
```

##### Advanced tip: reducing repetition {-}

Again, we could reduce some of the repetition above
using some of the advanced features of the [tidyverse](#tidyverse).
We could do:

```{r scaling_advanced, eval=FALSE}
real = real %>%
  mutate_at(c("NtTotal", "AsTotal", "ImpTotal", "SsTotal"),
            list(z = ~ scale(.)[, 1]))
```

##### Advanced tip: Scaling within groups {-}

If we want to check peoples' scores relative to the other participants
in their school, then we can scale the scores **within** each school.
Again, this is something that's easiest to handle using the
[tidyverse](#tidyverse):

```{r scale_in_schools, options}
real = real %>%
  group_by(SchoolId) %>%
  mutate(NtTotal_schoolz = scale(NtTotal)[, 1],
         AsTotal_schoolz = scale(AsTotal)[, 1],
         ImpTotal_schoolz = scale(ImpTotal)[, 1],
         SsTotal_schoolz = scale(SsTotal)[, 1]) %>%
  ungroup()

head(real[, c("SchoolId", "NtTotal", "NtTotal_z", "NtTotal_schoolz")])
```

#### Recoding using logical tests

For the BSI scales, we'll treat any score $> 10$ as showing a possible
diagnosis of depression or anxiety:

```{r bsi_diag_example, options}
dep_diagnosis = ifelse(real$DepTotal > 10, "Present", "Absent")
real$DepDiagnosis = factor(dep_diagnosis, levels = c("Absent", "Present"))

anx_diagnosis = ifelse(real$AnxTotal > 10, "Present", "Absent")
real$AnxDiagnosis = factor(anx_diagnosis, levels = c("Absent", "Present"))
```

For SURPS, we classify participants as **high risk** if 
they are more than 1 standard deviation above the mean on at 
least one subscale. First we need to express this as a logical test:

```{r high_risk_calc, options}
is_high_risk = (
  (real$NtTotal_z > 1) |
  (real$AsTotal_z > 1) |
  (real$ImpTotal_z > 1) |
  (real$SsTotal_z > 1)
)
```

Then we can convert the logical vector to a factor:

```{r high_risk_factor, options}
real$Risk = factor(is_high_risk, levels = c(FALSE, TRUE),
                   labels = c("Low", "High"))

head(real[, c("NtTotal_z", "AsTotal_z", "ImpTotal_z", "SsTotal_z", "Risk")])
```

#### Relationships between variables: Cleaning up alcohol variables {-}

The data here comes from an online survey, which was programmed so that questions
are skipped when they're no longer relevant. So if a participant has never
had a sip of alcohol, any questions about having a full drink of alcohol
are skipped because we can assume the answer is no.

You can see this logic in the plot below, which shows patterns of responses:

```{r alc_logic_plot, echo=FALSE}
alc_resps = c(
  "(Missing)", "No", "Yes", "Never", "Less than monthly",
  "Monthly", "1-2 times a month", "Weekly", "Daily"
)

resp_colours = c(
  "grey50",
  "#000000", "#2A788EFF",
  scales::viridis_pal(option = "B")(5)
)

real %>%
  ungroup() %>%
  select(PersonId, SipEver, FullEver, Sip6, Full6, Full6_freq) %>%
  mutate_at(vars(-PersonId), ~ factor(.) %>% fct_explicit_na()) %>% 
  count(SipEver, FullEver, Sip6, Full6, Full6_freq) %>%
  mutate(RowId = 1:n()) %>%
  pivot_longer(
    c(-RowId, -n),
    names_to = "Variable",
    values_to = "Response"
  ) %>%
  mutate(
    Variable = fct_inorder(factor(Variable)),
    Response = factor(Response, levels = alc_resps)) %>%
  ggplot(aes(x = Variable, y = RowId, fill = Response)) +
  geom_tile(colour = "black", size=0.4) +
  labs(y = "") +
  scale_y_reverse() +
  scale_fill_manual(values = resp_colours) +
  theme_minimal() +
  theme(axis.text.y = element_blank(),
        panel.grid = element_blank())
```

To get the same kind of overview in table form, you can also use `count()`:

```{r response_pattern_count, warning=FALSE}
count(real, SipEver, FullEver, Sip6, Full6, Full6_freq)
```

To analyse the data properly, we'll need to fill in the "No" responses that
can be assumed (because of the logic of the survey), instead of leaving
them missing.

There's no real trick to this, the hard part is getting a clear picture
of what needs to be done like we did above. As long as we fill in
the variables in order, we should get the right results:

```{r recode_logic_example, options}
# If they've never sipped, they've never had a full drink
#   and haven't sipped in the past 6 months
real$FullEver[real$SipEver == "No"] = "No"
real$Sip6[real$SipEver == "No"] = "No"

# If they haven't had a full drink ever, they haven't
#   had one in the past 6 months 
real$Full6[real$FullEver == "No"] = "No"

# If they haven't had a sip recently, they haven't
#   had a full drink 
real$Full6[real$Sip6 == "No"] = "No"

# If they haven't had a full drink, their frequency
#   of drinking is zero
real$Full6_freq[real$Full6 == "No"] = "Never"
```

If we look at the pattern of responses again we should see that
all the relevant responses have now bene filled in. Where
missing values remain, it's because we can't automatically
assume a response:

```{r alc_logic_plot_after, echo=FALSE}
real %>%
  ungroup() %>%
  select(PersonId, SipEver, FullEver, Sip6, Full6, Full6_freq) %>%
  mutate_at(vars(-PersonId), ~ factor(.) %>% fct_explicit_na()) %>% 
  count(SipEver, FullEver, Sip6, Full6, Full6_freq) %>%
  mutate(RowId = 1:n()) %>%
  pivot_longer(
    c(-RowId, -n),
    names_to = "Variable",
    values_to = "Response"
  ) %>%
  mutate(
    Variable = fct_inorder(factor(Variable)),
    Response = factor(Response, levels = alc_resps)) %>%
  ggplot(aes(x = Variable, y = RowId, fill = Response)) +
  geom_tile(colour = "black", size=0.4) +
  labs(y = "") +
  scale_y_reverse() +
  scale_fill_manual(values = resp_colours) +
  theme_minimal() +
  theme(axis.text.y = element_blank(),
        panel.grid = element_blank())
```

## Saving data

Now that the data has been recoded and cleaned, we
can save it. R can output to lots of different formats,
so you can choose whichever format works best for you.

However, if you want to keep working in R, it's best
to save it in a format that preserves all the info
about your data, including the order of categories
in your factors. SPSS and Stata formats will do this,
while Excel won't. For now, we'll use R's own
**.rds** format, which preserves all that information:

```{r save_rds_example, eval=FALSE}
readr::write_rds(real, "CapData-Recoded.rds")
```

## Descriptive statistics

Once our data has been recoded and cleaned, we can
start looking at descriptive statistics - this
is always a good first step before trying any actual
analysis.

### Correlations between variables

We can get a good overview of the relationships between
different variables using a **scatterplot matrix**,
which shows correlations between each pair of variables.
`psych` has a function `pairs.panel` to handle this:

```{r scatter_matrix_example, dev='png'}
key_vars = c("NtTotal_z", "AsTotal_z", "ImpTotal_z", 
             "SsTotal_z", "DepTotal", "AnxTotal")
psych::pairs.panels(real[, key_vars])
```

```{block, type='note'}
Also check out the `ggcorrplot` package for a nicer-looking
version of this.
```

If we want a traditional correlation table, we can use
`psych::corr.test`, which provides both the correlations
between variables and the *p* values for each correlation
coefficient.

```{r real_corr_table_example, options}
psych::corr.test(real[, key_vars])
```

### Contingency tables for categorical data

To generate cross-tabs or contigency tables for categorical
variables, we can use `table()`, which we've already seen
earlier:

```{r real_crosstab_example, options}
table(real$Group, real$Sex)
```

If we want to do some basic testing to see if the
proportions of males and females differ, we can use `chisq.test()`

```{r real_chisq_example, options}
chisq.test(real$Group, real$Sex)
```

If we wanted to visualize these numbers instead,
that's easy to achieve in `ggplot`:

```{r real_ggplot_bar_example, fig.width=5, fig.height=4}
ggplot(real, aes(x = Group, fill = Sex)) +
    geom_bar(position = 'dodge', colour = 'black')
```

### Understanding complex data

Before trying to do analysis, it can be useful to try
to understand some of the more complex features of your
data. In this study, one important feature is the 
cluster randomization, where participants are grouped
in schools - we'll need to account for this in our analysis
so it's worth trying to get a picture of how it looks.

We'll try to look at the means of some variables in each
school. Complex grouped data like this is where the
`tidyverse` starts to be really useful, so we'll
start making heavy use of it. We'll start by generating
a table:

```{r complex_mean_table, options}
dep_tab = real %>%
  group_by(Group, SchoolId) %>%
  summarize(
    DepMean = mean(DepTotal, na.rm = TRUE),
    SchoolSize = n()
  )

head(dep_tab)
```

Once we've got this information in a table, it's
easy to create a `ggplot` plot to visualize it

```{r complex_mean_plot, dev='png'}
ggplot(dep_tab, aes(x = Group, y = DepMean, 
                    colour = Group)) +
  geom_jitter(aes(size = SchoolSize), alpha= 0.5,
              width = 0.1, height = 0)
```

```{block, type='note'}
You can calculate means and summaries within `ggplot2`,
feeding in your full dataset and  using functions like 
`stat_summary()`. But I'd recommend
using `tidyverse` functions to create a simple summary
table instead,as you'll often run into things `ggplot`
can't do without a lot of effort.
```

## Analysis

### Simple but wrong: Logistic regression

We'll start with a simple analysis, just comparing
the **odds** of drinking (a binary outcome) between
the groups. Since this is a binary outcome,
we'll use logistic regression, which is available
in R through the `glm()` function. This isn't quite
the right approach here, since it doesn't account
for potential correlations between participants in
the same school.

`glm()` works similarly to `lm()`, which we saw earlier:
we spell out our model using a formula like `outcome ~ predictors`.
For logistic regression we also have to specify 
`family = binomial(link = 'logit')`, since that's the distribution
we're using to model the binary outcomes:

```{r simple_glm_example, options}
simple_glm = glm(
  Full6 ~ Group,
  data = real,
  family = binomial(link = "logit")
)

summary(simple_glm)
```

#### Better output with `tab_model()` {-}

While `summary()` gives us lots of useful info about
the model, it's not particularly readable or nice looking.
We'll use `tab_model()` for nicer output:

```{r simple_glm_tab_model, options}
tab_model(simple_glm)
```

#### Visualizing our model with `plot_model()` {-}

It can be difficult to understand how logistic
regression relates to the actual probability
of the outcome. Thankfully `plot_model()` can
automatically convert the intervention
effect in the model to **predicted probabilities**:

```{r simple_glm_plot_model, fig.width=5, fig.height=4}
plot_model(simple_glm,
           type = "pred",
           terms = "Group")
```

### More complex modelling: Mixed models with `lme4`

To account for the clustering in the data,
we'll use a **mixed model** from the `lme4`
package. Adapting our model from above to
the mixed model approach doesn't require
many changes, since the models use basically
the **same syntax** and we can use some
of the same **reporting and visualization
tools** to help interpret them.

Instead of the `glm()` function, we'll use `glmer()`
from the `lme4` package. To add **random intercepts** 
for each school into the model, we just need to tweak
the syntax slightly:

```{r glmer_example, options}
mixed_glm = glmer(
  Full6 ~ Group + (1 | SchoolId),
  data = real,
  family = binomial(link = "logit")
)

summary(mixed_glm)
```

#### Using `tab_model()` again

```{r glmer_tab_model, options}
tab_model(mixed_glm)
```

#### And `plot_model()` again

```{r glmer_plot_model, fig.width=5, fig.height=4}
plot_model(mixed_glm,
           type = 'pred',
           terms = 'Group')
```